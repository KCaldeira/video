# video to midi code
"""
prompt for ChatGTP:

Here's a Python script that processes every Nth frame of a video file, calculates multiple metrics (average intensity, 
standard deviation, and entropy) for each color color_channel_name (R, G, B, and grayscale) and outputs 24 MIDI files. 
Each metric is stored in two MIDI files: one directly scaled (0-127) and another inverted (127-0).

This script will:

Extract every Nth frame from the video.
Compute various metrics for each color channel.
Map values to MIDI Control Change (CC) messages (both direct and inverted).
Save each metric in a separate MIDI file, with filenames autogenerated.

"""
import cv2
import os
import pandas as pd
import numpy as np
import re
from mido import Message, MidiFile, MidiTrack
from scipy.stats import rankdata
from collections import defaultdict

def compute_dark_light_metric(color_channel, tolerance = 0):
    """
    Compute the number of pixels equal to the darkest and lightest values in each frame
    """
    # find the darkest and lightest values in the color channel
    dark_value = np.min(color_channel)
    light_value = np.max(color_channel)
    # count the number of pixels that are darker or equal to dark_value plus tolerance
    dark_count = np.sum(color_channel <= dark_value + tolerance)
    # count the number of pixels that are lighter or equal to light_value minus tolerance
    light_count = np.sum(color_channel >= light_value - tolerance)
    # return the number of pixels equal to the darkest and lightest values
    return dark_count, light_count

def line_symmetry_metric(color_channel, downscale_factor):
    """
    If there were a set of concentric circles in the image, then any vertical or horizontal slice should have a symmetry around some point.
    It would be the central point if the concentric circles were at the center of the image.
    
    The algorithm sweeps through all vertical lines in the central 50% of the image and then all horizontal lines in the central 50% of the image.
    For each line segment, the maximum correlation between the left and right parts of the line segment are computed.
    """
    # if uniform color return zeros
    if np.max(color_channel) == np.min(color_channel):
        return 0.0, 0.0, 0.0

    # Original size
    h, w = color_channel.shape[0:2]

    # Downscale and then upscale
    downscaled  = cv2.resize(color_channel, (w // downscale_factor, h // downscale_factor), interpolation=cv2.INTER_AREA)
    hd, wd = downscaled.shape[0:2]

    corrlistx = []
    # sweep through all vertical lines in the central 50% of the image
    for ix in range(wd//4, 3*wd//4):
        vec = downscaled[:, ix]
        corrlist_column = []
        half_height = hd // 4
        for iy in range(half_height, 3*half_height):
            try:
                left_vec = vec[iy - half_height:iy][::-1]
                right_vec = vec[iy + 1:iy + 1 + half_height]
                # Check if vectors are too short or have zero variance
                if len(left_vec) < 2 or len(right_vec) < 2 or \
                   np.var(left_vec) == 0 or np.var(right_vec) == 0:
                    corr = 0.0
                else:
                    with np.errstate(divide='ignore', invalid='ignore'):
                        corr = np.corrcoef(left_vec, right_vec)[0, 1]
                    if np.isnan(corr):
                        corr = 0.0
                corrlist_column.append(corr)
            except:
                corrlist_column.append(0.0)
        corrlistx.append(max(0.0, max(corrlist_column)))

    corrlisty = []
    # sweep through all horizontal lines in the central 50% of the image
    for iy in range(hd//4, 3*hd//4):
        vec = downscaled[iy, :]
        corrlist_column = []
        half_width = wd // 4
        for ix in range(half_width, 3*half_width):
            try:
                left_vec = vec[ix - half_width:ix][::-1]
                right_vec = vec[ix + 1:ix + 1 + half_width]
                # Check if vectors are too short or have zero variance
                if len(left_vec) < 2 or len(right_vec) < 2 or \
                   np.var(left_vec) == 0 or np.var(right_vec) == 0:
                    corr = 0.0
                else:
                    with np.errstate(divide='ignore', invalid='ignore'):
                        corr = np.corrcoef(left_vec, right_vec)[0, 1]
                    if np.isnan(corr):
                        corr = 0.0
                corrlist_column.append(corr)
            except:
                corrlist_column.append(0.0)
        corrlisty.append(max(0.0, max(corrlist_column)))

    # Compute statistics
    mediancorrx = np.median(corrlistx)
    mediancorry = np.median(corrlisty)
    mediancorr = np.sqrt(mediancorrx * mediancorry)
    # 10th percentiles
    tenthcorrx = np.percentile(corrlistx, 10)
    tenthcorry = np.percentile(corrlisty, 10)
    tenthcorr = np.sqrt(tenthcorrx * tenthcorry)
    # 90th percentile
    ninetiethcorrx = np.percentile(corrlistx, 90)
    ninetiethcorry = np.percentile(corrlisty, 90)   
    ninetiethcorr = np.sqrt(ninetiethcorrx * ninetiethcorry)

    return mediancorr, tenthcorr, ninetiethcorr

def tranpose_metric(color_channel, downscale_factor):
    """
    Returns a metric of information loss when a color channel from a frame 
    is downscaled and then upscaled.
    
    frame: color channel (e.g., R, G, B, or grayscale)
    downscale_factor: how much to shrink (e.g., 4 means 1/4 size)
    """

    # Original size
    h, w = color_channel.shape[0:2]

    # Downscale and then upscale
    downscaled  = cv2.resize(color_channel, (w // downscale_factor, h // downscale_factor), interpolation=cv2.INTER_AREA)

    # Compute mean squared error (MSE) between original and restored image
    mse = np.mean((downscaled - downscaled[::-1,::-1]) ** 2)

    # Optional: normalize MSE to 0–1 by dividing by max possible value (variance)
    normalized_mse =  mse / (np.var(downscaled) + 1e-6)  # avoid division by zero
    # 1 means perfect symmetry at this scale 
    # 0 means no symmetry at this scale

    return normalized_mse

def reflect_metric(color_channel, downscale_factor=4):
    """
    Returns a metric of information loss when a color channel from a frame 
    is downscaled and then upscaled.
    
    frame: color channel (e.g., R, G, B, or grayscale)
    downscale_factor: how much to shrink (e.g., 4 means 1/4 size)
    """

    # Original size
    h, w = color_channel.shape[0:2]

    # Downscale and then upscale
    downscaled  = cv2.resize(color_channel, (w // downscale_factor, h // downscale_factor), interpolation=cv2.INTER_AREA)

    # Compute mean squared error (MSE) between original and vertically reflected image
    mse0 = np.mean((downscaled - downscaled[::-1]) ** 2)

    # Compute mean squared error (MSE) between original and horizontally reflected image
    mse1 = np.mean((downscaled - downscaled[:,::-1]) ** 2)

    # Optional: normalize MSE to 0–1 by dividing by max possible value (variance)
    normalized_mse = (mse0 + mse1) / (2. * (np.var(downscaled) + 1e-6)) # avoid division by zero
    # 1 means perfect symmetry at this scale 
    # 0 means no symmetry at this scale

    return normalized_mse

def radial_symmetry_metric(color_channel, dowscale_factor):
    """
    Compute radial symmetry metric for a color channel with distance bins of width `scale_factor`.
    """
    # Step 1: Create coordinate grid
    y, x = np.indices(color_channel.shape)
    center_y = (color_channel.shape[0] / 2) - 0.5
    center_x = (color_channel.shape[1] / 2) - 0.5

    # Step 2: Compute radial distance from center for each pixel
    r = np.sqrt((x - center_x)**2 + (y - center_y)**2)

    # Step 2b: Bin distances into scale_factor-wide bins
    r_bin = (r / dowscale_factor).astype(np.int32)

    # Step 3: Compute mean value for each radial bin
    max_bin = r_bin.max()
    radial_mean = np.zeros(max_bin + 1)
    counts = np.bincount(r_bin.ravel())
    sums = np.bincount(r_bin.ravel(), weights=color_channel.ravel())

    # Avoid division by zero
    with np.errstate(divide='ignore', invalid='ignore'):
        radial_mean[:len(sums)] = np.where(counts != 0, sums / counts, 0)

    # Optional: remove zeros or masked bins if they skew the variance
    # valid = counts > 0
    # return np.var(radial_mean[valid])

    return np.var(radial_mean)

def weighted_std(values, weights):
    """
    Calculate weighted standard deviation
    
    Parameters:
    - values: array of values
    - weights: array of weights (must be same length as values)
    
    Returns:
    - weighted standard deviation
    """
    # Calculate weighted mean
    if np.sum(weights) == 0:
        return 0.0
    weighted_mean = np.average(values, weights=weights)
    
    # Calculate weighted variance
    weighted_variance = np.average((values - weighted_mean)**2, weights=weights)
    
    # Return standard deviation (square root of variance)
    return np.sqrt(weighted_variance)

def error_dispersion_metrics(color_channel, downscale_factor):
    """
    Detect circles in a color channel using Hough Transform.
    Returns metrics indicating the presence, size, and robustness of circles.
    
    Parameters:
    - color_channel: color channel
    - downscale_factor: Scale factor for downscaling before detection
    - downscale_medium: Scale factor for downscaling before detection
    
    Returns:
    - non_normalized_circle_metric0: Sum of circle confidences
    - non_normalized_circle_metric2: Sum of (radius^2 * confidence)
    - non_normalized_circle_metric4: Sum of (radius^4 * confidence)
    - n_circles: Number of circles detected
    - area_circles: Total area of detected circles
    - circle_confidences: List of confidence values for each circle
    """
    # if uniform color return zeros
    if np.max(color_channel) == np.min(color_channel):
        return 0.0, 0.0, 0.0, 0.0, 0.0, 0.0
    h, w = color_channel.shape[0:2]

    # Downscale and then upscale
    downscaled1  = cv2.resize(color_channel, (w // downscale_factor, h // downscale_factor), interpolation=cv2.INTER_AREA)
    restored1 = cv2.resize(downscaled1, (w, h), interpolation=cv2.INTER_LINEAR)

    xvals = np.arange(0, w)
    yvals = np.arange(0, h)

    centerx = w/2
    centery = h/2   

    X, Y = np.meshgrid(xvals, yvals)

    # what is the magnitude of the lowres error?
    # how far is the lowres error from the center of the image?
    # how far is the highres error from the center of the image?
    # how dispersed is the low res error around the center of the low res error?
    # how dispersed is the high res error around the center of the high res error?
    # _std is the standard deviation of the variability of the channel.
    # now let's see what is the standard deviation 
    # convert Nan's to zeros in color_channel
    # color_channel = np.where(np.isnan(color_channel), 0, color_channel)
    info_total = np.var(color_channel)
    info_large = (restored1 - np.mean(color_channel))**2 / (info_total + 1e-6) # fraction of variance in large scale
    info_small = (color_channel - restored1)**2 / (info_total + 1e-6) # fraction of variance in small scale


    # Compute mean squared error (MSE) between original and restored image
    meanx1 = np.average( X, weights= info_large)
    meanx2 = np.average( X, weights= info_small)
 
    meany1 = np.average( Y, weights= info_large)
    meany2 = np.average( Y, weights= info_small)

    stddevx1 = weighted_std( X, info_large)
    stddevx2 = weighted_std( X, info_small)
    stddevy1 = weighted_std( Y, info_large)
    stddevy2 = weighted_std( Y, info_small)

    mnsqerror1 = np.average(info_large)
    mnsqerror2 = np.average(info_small)

    dist1 = np.sqrt((meanx1 - centerx)**2 + (meany1 - centery)**2)
    dist2 = np.sqrt((meanx2 - centerx)**2 + (meany2 - centery)**2)


    stdev1 = np.sqrt(stddevx1**2 + stddevy1**2)
    stdev2 = np.sqrt(stddevx2**2 + stddevy2**2)


    return mnsqerror1, mnsqerror2, dist1, dist2, stdev1, stdev2 


def bgr_to_hsv(b, g, r):
    """
    Convert RGB to HSV for 2D numpy arrays.
    Inputs r, g, b: 2D numpy arrays with values in [0, 255]
    Outputs h in degrees [0, 360), s and v in [0.0, 1.0]
    """
    r = r.astype(np.float32) / 255
    g = g.astype(np.float32) / 255
    b = b.astype(np.float32) / 255

    cmax = np.maximum.reduce([r, g, b])
    cmin = np.minimum.reduce([r, g, b])
    delta = cmax - cmin

    # Hue calculation
    h = np.zeros_like(cmax)

    mask = delta != 0
    r_max = (cmax == r) & mask
    g_max = (cmax == g) & mask
    b_max = (cmax == b) & mask

    h[r_max] = (60 * ((g[r_max] - b[r_max]) / delta[r_max])) % 360
    h[g_max] = (60 * ((b[g_max] - r[g_max]) / delta[g_max]) + 120)
    h[b_max] = (60 * ((r[b_max] - g[b_max]) / delta[b_max]) + 240)

    # Saturation calculation
    s = np.zeros_like(cmax)
    nonzero = cmax != 0
    s[nonzero] = delta[nonzero] / cmax[nonzero]

    # Value
    v = cmax

    return h, s, v

# Circular statistics function to compute standard deviation of angle weighted by saturation
# Hue is assumed to be 0-360 degrees, saturation is 0-1
def weighted_circular_std_deg(hue, saturation):
    """Weighted circular standard deviation in degrees"""
    angles_rad = np.deg2rad(hue)
    weights = np.array(saturation)
    z = weights * np.exp(1j * angles_rad)
    R_w = np.abs(np.sum(z) / (np.sum(weights) + 1e-6)) # avoid division by zero
    return np.rad2deg(np.sqrt(-2 * np.log(R_w)))





def compute_basic_metrics(frame, downscale_large, downscale_medium):
    """
    Compute different intensity-based metrics on R, G, B, and color channels.
    Returns a dictionary of results.
    """
    basic_metrics = {}
    
    b, g, r = cv2.split(frame)
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    h, s, v = bgr_to_hsv(b, g, r)

    # Split into R, G, B channels
    for color_channel_name, color_channel in [("R", r), ("G", g), ("B", b),
                                ("Gray", gray),("S", s),("V", v)]:
        avg_intensity = np.mean(color_channel)
        variance = np.var(color_channel)


        transpose_metric_value = tranpose_metric(color_channel, downscale_medium) # degree of symmettry for flipping around the center point
        # at the specified spatial scale
        reflect_metric_value = reflect_metric(color_channel, downscale_medium) # degree of symmettry for flipping around the center point
        # at the specified spatial scale
        radial_symmetry_metric_value = radial_symmetry_metric(color_channel, downscale_medium) # degree of symmettry for flipping around the center point
        # at the specified spatial scale

        # Add error detection metrics
        mnsqerror1, mnsqerror2, dist1, dist2, stdev1, stdev2 = error_dispersion_metrics(color_channel, downscale_large)
        # Add line symmetry metrics, aimed at detecting circles in an image
        mediancorr, tenthcorr, ninetiethcorr = line_symmetry_metric(color_channel, downscale_medium)

        dark_count, light_count = compute_dark_light_metric(color_channel, 5) # needs to be within 5 (0 - 255) unites of max or min light or dark values


        # Store values
        basic_metrics[f"{color_channel_name}_avg"] = avg_intensity
        basic_metrics[f"{color_channel_name}_var"] = variance # note that variance is total info (i.e., diff^2 relative to mean)
        basic_metrics[f"{color_channel_name}_xps"] = transpose_metric_value
        basic_metrics[f"{color_channel_name}_rfl"] = reflect_metric_value
        basic_metrics[f"{color_channel_name}_rad"] = radial_symmetry_metric_value
        basic_metrics[f"{color_channel_name}_ee1"] = mnsqerror1  # how much low res detail?
        basic_metrics[f"{color_channel_name}_ee2"] = mnsqerror2  # How much high res detail?
        basic_metrics[f"{color_channel_name}_ed1"] = dist1  # distance of low res error from center of image
        basic_metrics[f"{color_channel_name}_ed2"] = dist2  # distance of high res error from center of image
        basic_metrics[f"{color_channel_name}_es1"] = stdev1  # How much spatial variation in low res detail
        basic_metrics[f"{color_channel_name}_es2"] = stdev2  # How much spatial variation in high res detail
        basic_metrics[f"{color_channel_name}_lmd"] = mediancorr
        basic_metrics[f"{color_channel_name}_l10"] = tenthcorr
        basic_metrics[f"{color_channel_name}_l90"] = ninetiethcorr
        basic_metrics[f"{color_channel_name}_dcd"] = dark_count
        basic_metrics[f"{color_channel_name}_dcl"] = light_count


    #monochrome metric is the standard deviation of hue weighted by saturation
    # take negative so high value means a high degree of monotonicity
    basic_metrics["Hmon_std"] = -weighted_circular_std_deg(h, s)

    # measure the degree to which the hue is close to each of the 6 cardinal hues
    # take negative so high value means high presencee of that color
    basic_metrics["H000_std"] = -np.mean((((h + 180 - 0) % 360) - 180)**2)**(1/2)
    basic_metrics["H060_std"] = -np.mean((((h + 180 - 60) % 360) - 180)**2)**(1/2)
    basic_metrics["H120_std"] = -np.mean((((h + 180 - 120) % 360) - 180)**2)**(1/2)
    basic_metrics["H180_std"] = -np.mean((((h + 180 - 180) % 360) - 180)**2)**(1/2)    
    basic_metrics["H240_std"] = -np.mean((((h + 180 - 240) % 360) - 180)**2)**(1/2)  
    basic_metrics["H300_std"] = -np.mean((((h + 180 - 300) % 360) - 180)**2)**(1/2)

    return basic_metrics

# Export metrics to CSV
def export_metrics_to_csv(frame_count_list, metrics, filename):
    """
    Export frame count and metric data to a CSV file using pandas,
    with metrics sorted alphabetically by key.

    Parameters:
    - frame_count_list (list): List of frame counts.
    - metrics (dict): Dictionary where each value is a list of the same length as frame_count_list.
    - filename (str): Name of the CSV file to write.
    """

    # Sort the metric keys alphabetically
    sorted_keys = sorted(metrics.keys())

    # Create a DataFrame using the sorted keys
    data = {'frame_count_list': frame_count_list}
    for key in sorted_keys:
        data[key] = metrics[key]

    df = pd.DataFrame(data)
    df.to_csv(filename, index=False)

def process_video_to_csv(video_path, 
                          subdir_name, # output prefix 
                          frames_per_second, 
                          beats_per_midi_event,
                          ticks_per_beat, 
                          beats_per_minute, 
                          downscale_large,
                          downscale_medium):
    """
    Process every Nth frame, calculate metrics, and generate multiple MIDI files.
    
    :param video_path: Path to the video file.
    :param output_prefix: Prefix for output MIDI filenames.
    :param frames_per_second (number of frames per second in video)
    :param beats_per_midi_event (number of beats between each frame that will per processed)
    :param ticks_per_beat (number of midi ticks per beat in DAW)
    :param beats_per_minute (number of beats per minute in DAW)
    :param cc_number: MIDI CC number (default 7 for volume).
    :param channel: MIDI channel (0-15).
    :param downscale_large: spatial scale for computing metrics
    :param downscale_medium: resolution reduction for computing metrics
    :param filter_width: width of boxcar filter for smoothing

    """




    ticks_per_frame = ticks_per_beat *( beats_per_minute / 60.) / frames_per_second # ticks per second / frames per second
    # Calculate the frame interval for processing frames
    seconds_per_analysis_frame = beats_per_midi_event / (beats_per_minute / 60) # beats per frame / beats per second
    frames_per_analysis_frame_real = seconds_per_analysis_frame * frames_per_second
    # Take every Nth frame, where frames_per_interval_real is the floating point non-integer version of N

    frame_count = 0
    frame_count_list = []

    # Define metric categories that get computed by <compute_metrics>
    # and the color channels that get computed
    metric_names = ["avg", "var", "xps", "rfl", "rad", "ee1","ee2","ed1","ed2","es1","es2","lmd","l10","l90","dcd","dcl"]
    color_channel_names = ["R", "G", "B", "Gray","S","V"]
    basic_metrics = {f"{color_channel_name}_{metric_name}": [] 
               for color_channel_name in color_channel_names for metric_name in metric_names}
    # add metrics that are outside of the normal grouping
    basic_metrics["Hmon_std"] = []
    basic_metrics["H000_std"] = []
    basic_metrics["H060_std"] = []
    basic_metrics["H120_std"] = []
    basic_metrics["H180_std"] = []
    basic_metrics["H240_std"] = []
    basic_metrics["H300_std"] = []

    # open the video file
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Error: Could not open video file.")
        return
    
    # Get total number of frames in the video
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    print(f"Total frames in video: {total_frames}")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        k = frame_count / frames_per_analysis_frame_real
        k_rounded = round(k)
        frame_count_good = round(k_rounded * frames_per_analysis_frame_real)
        if frame_count == frame_count_good or frame_count == total_frames - 1:
            print ("Processing frame:", frame_count)
            frame_count_list.append(frame_count)

            metric_results = compute_basic_metrics(frame, downscale_large, downscale_medium)

            #append to the dictionary of results
            for key, value in metric_results.items():
                basic_metrics[key].append(value)

        frame_count += 1

    cap.release()

    #now compute derivative metrics that are computed after all frames are processed
    basic_metrics["Hmon_std"] = np.array(basic_metrics["Hmon_std"])
    if np.max(basic_metrics["Hmon_std"]) == 0.0:
        diff_monos = 0.0
    else:
        diff_monos =   1.0 - basic_metrics["Hmon_std"] / np.max(basic_metrics["Hmon_std"])

    for key in ["H000_std", "H060_std", "H120_std", "H180_std", "H240_std", "H300_std"]:
        basic_metrics[key] = np.array(basic_metrics[key])
        # replace trailing s in key with i      
        key_i = key.replace("_std", "_int")  # i for intensity !
        basic_metrics[key_i] = (180 - basic_metrics[key]) * diff_monos

    # Export metrics to CSV
    csv_filename = f"{subdir_name}_basic.csv"
    export_metrics_to_csv(frame_count_list, basic_metrics, csv_filename)
    print(f"Metrics exported to {csv_filename}")

    




# Example usage
#video_file = "Mz3DllgimbrV2.wmv"  #  small test video file
#subdir_name = "Mz3DllgimbrV2" # output prefix
#video_file = "He saw Julias everywhere (MzJuliaV2e).wmv"
#video_file = "Mz3DllgimbrV2B.wmv"
#subdir_name = "Mz3DllgimbrV2B" # output prefix
#video_file = "M10zul.mp4"
#subdir_name = "M10zul" # output prefix
#video_file = "JuliaInJulia-Mzljdjb6fa2f.wmv"
#subdir_name = "JuliaInJulia" # output prefix
#video_file = "MzUL2-5jm3f.wmv"
#subdir_name = "MzUL2-5jm3f" # output prefix
#video_file = "WhatsApp Video 2023-09-06 at 7.38.17 AM.mp4"
#subdir_name = "WhatsApp" # output prefix
#video_file = "N3_M5zulPentAf2-V3A.wmv"
#subdir_name = "N3_M5zulPentAf2-V3A" # output prefix 
#video_file = "N2_M3toBSy25f-1.wmv"
#subdir_name = "N2_M3toBSy25f-1" # output prefix 
#video_file = "N6_BSt-3DAf.wmv"
#subdir_name = "N6_BSt-3DAf" # output prefix 
#video_file = "N8_M3toM2µa7fC2.wmv"
#subdir_name = "N8_M3toM2µa7fC2" # output prefix 
#video_file = "N11_M8zaf-Cdeg-1.wmv"  
#subdir_name = "N11_M8zaf-Cdeg-1" # output prefix 
#video_file = "N9B_M6tonM2ta5f-2.wmv"
#subdir_name = "N9B_M6tonM2ta5f-2" # output prefix 
#video_file = "N1_Mzlcgt4f-Cn.wmv"
#subdir_name = "N1_Mzlcgt4f-Cn" # output prefix     
#video_file = "N12_sinz2-3j2fv.wmv"
#subdir_name = "N12_sinz2-3j2fv" # output prefix
video_file = "N12_sinz2-3j2f.wmv"
subdir_name = "N12_sinz2-3j2f" # output prefix

process_video_to_csv(video_file, 
                      subdir_name, # output prefix 
                      frames_per_second=30, 
                      beats_per_midi_event=1,
                      ticks_per_beat=480, 
                      beats_per_minute=100,  
                      downscale_large=100, # scale boundary means divide so 100x100 pixels in a cell (approximately square root of width and height of video)
                      downscale_medium=10 ) # resolution reduction means divide so 10x10 pixels in a cell (approximately square root of the larger scale)
# process_video_to_csv("path_to_your_video.mp4", "output_prefix", nth_frame=30, frames_per_second=30, ticks_per_beat=480, beats_per_minute=120, cc_number=7, channel=0)

