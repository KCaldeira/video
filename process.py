# video to midi code
"""
prompt for ChatGTP:

Here's a Python script that processes every Nth frame of a video file, calculates multiple metrics (average intensity, 
standard deviation, and entropy) for each color color_channel (R, G, B, and grayscale) and outputs 24 MIDI files. 
Each metric is stored in two MIDI files: one directly scaled (0-127) and another inverted (127-0).

This script will:

Extract every Nth frame from the video.
Compute various metrics for each color channel.
Map values to MIDI Control Change (CC) messages (both direct and inverted).
Save each metric in a separate MIDI file, with filenames autogenerated.

"""
import cv2
import numpy as np
from mido import Message, MidiFile, MidiTrack
import os
from scipy.stats import entropy

def compute_metrics(frame):
    """
    Compute different intensity-based metrics on R, G, B, and grayscale images.
    Returns a dictionary of results.
    """
    metrics = {}

    # Convert to grayscale
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Split into R, G, B channels
    b, g, r = cv2.split(frame)

    for name, color_channel in [("R", r), ("G", g), ("B", b), ("Gray", gray_frame)]:
        # Compute metrics
        avg_intensity = np.mean(color_channel)
        std_dev = np.std(color_channel)
        
        # Compute entropy (measure of randomness)
        hist = cv2.calcHist([color_channel], [0], None, [256], [0, 256])
        hist_prob = hist / hist.sum()
        entropy_val = entropy(hist_prob, base=2)[0]

        # Store values
        metrics[f"{name}_avg"] = avg_intensity
        metrics[f"{name}_std"] = std_dev
        metrics[f"{name}_entropy"] = entropy_val

    return metrics

def process_video_to_midi(video_path, 
                          output_prefix, 
                          frames_per_second=30, 
                          beats_per_frame=4,
                          ticks_per_beat=480, 
                          beats_per_minute=120, 
                          cc_number=7, 
                          midi_channel=0):
    """
    Process every Nth frame, calculate metrics, and generate multiple MIDI files.
    
    :param video_path: Path to the video file.
    :param output_prefix: Prefix for output MIDI filenames.
    :param frames_per_second (number of frames per second in video)
    :param beats_per_frame (number of beats between each frame that will per processed)
    :param ticks_per_beat (number of midi ticks per beat in DAW)
    :param beats_per_minute (number of beats per minute in DAW)
    :param cc_number: MIDI CC number (default 7 for volume).
    :param channel: MIDI channel (0-15).

    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Error: Could not open video file.")
        return

    # Define metric categories
    metric_names = ["avg", "std", "entropy"]
    color_channels = ["R", "G", "B", "Gray"]

    ticks_per_frame = ticks_per_beat * beats_per_frame
    # Calculate the frame interval for processing frames
    seconds_per_interval = beats_per_frame / (beats_per_minute / 60)
    frames_per_interval_real = seconds_per_interval * frames_per_second
    # Take every Nth frame, where frames_per_interval_real is the floating point non-integer version of N

    frame_count = 0
    frame_count_list = []


    # assemble dictionary of results for metrics
    metrics = {f"{color_channel}_{metric}": [] for color_channel in color_channels for metric in metric_names}
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        k = frame_count / frames_per_interval_real
        k_rounded = round(k)
        frame_count_good = round(k_rounded * frames_per_interval_real)
        if frame_count == frame_count_good :
            print ("Processing frame:", frame_count)
            frame_count_list.append(frame_count)

            metric_results = compute_metrics(frame)

            #append to the dictionary of results
            for key, value in metric_results.items():
                metrics[key].append(value)

        frame_count += 1

    cap.release()

    # normalize all metrics to be between 0 and 1
    for key, values in metrics.items():
        metric = np.array(values)
        max_val = np.max(metric)
        min_val = np.min(metric)
        normalized_metric = (metric - min_val) / (max_val - min_val)
        metrics[key] = normalized_metric.tolist()

    # Initialize MIDI files for each metric
    midi_files = {}
    for color_channel in color_channels:
        for metric in metric_names:
            base_filename = f"{output_prefix}_{color_channel}_{metric}"
            midi_files[f"{color_channel}_{metric}"] = MidiFile()
            midi_files[f"{color_channel}_{metric}_inv"] = MidiFile()

            # Add MIDI tracks
            midi_files[f"{color_channel}_{metric}"].tracks.append(MidiTrack())
            midi_files[f"{color_channel}_{metric}_inv"].tracks.append(MidiTrack())

    # Write MIDI messages for each metric
    for key, value in metrics.items():
        midi_val = [round(127 * val) for val in value] # Scale to MIDI range (0-127)
        # Invert the MIDI value for the second file
        midi_val_inv = [round(127 * (1-val)) for val in value]

        # Add to the correct MIDI track
        color_channel_name, metric_name = key.split("_")
        for i, midi_value in enumerate(midi_val):
            if i == 0:
                time_tick = 0
            else:
                time_tick = int(ticks_per_frame * (frame_count_list[i] -frame_count_list[i-1]) )
            midi_files[f"{color_channel_name}_{metric_name}"].tracks[0].append(
                Message('control_change', 
                        control=cc_number, 
                        value=midi_value, 
                        channel=midi_channel, 
                        time=time_tick)
            )
        for i, midi_value_inv in enumerate(midi_val_inv):
            if i == 0:
                time_tick = 0
            else:
                time_tick = int(ticks_per_frame * (frame_count_list[i] -frame_count_list[i-1]) )


            midi_files[f"{color_channel_name}_{metric_name}_inv"].tracks[0].append(
                Message('control_change', 
                        control=cc_number, 
                        value=midi_value_inv, 
                        channel=midi_channel, 
                        time=time_tick)
            )






    # Save all MIDI files
    for key, midi_file in midi_files.items():
        filename = f"{output_prefix}_{key}.mid"
        midi_file.save(filename)
        print(f"Saved: {filename}")

# Example usage
test_video = "Mz3DllgimbrV2.wmv"

process_video_to_midi(test_video, 
                      "test_midi", 
                      frames_per_second=30, 
                      beats_per_frame=4,
                      ticks_per_beat=480, 
                      beats_per_minute=120, 
                      cc_number=7, 
                      midi_channel=0)
# process_video_to_midi("path_to_your_video.mp4", "output_prefix", nth_frame=30, frames_per_second=30, ticks_per_beat=480, beats_per_minute=120, cc_number=7, channel=0)

