# video to midi code
"""
prompt for ChatGTP:

Here's a Python script that processes every Nth frame of a video file, calculates multiple metrics (average intensity, 
standard deviation, and entropy) for each color color_channel (R, G, B, and grayscale) and outputs 24 MIDI files. 
Each metric is stored in two MIDI files: one directly scaled (0-127) and another inverted (127-0).

This script will:

Extract every Nth frame from the video.
Compute various metrics for each color channel.
Map values to MIDI Control Change (CC) messages (both direct and inverted).
Save each metric in a separate MIDI file, with filenames autogenerated.

"""
import cv2
import numpy as np
from mido import Message, MidiFile, MidiTrack
from scipy.stats import rankdata

def information_metric(color_channel, downscale_factor=4):
    """
    Returns a metric of information loss when a color channel from a frame 
    is downscaled and then upscaled.
    
    frame: color channel (e.g., R, G, B, or grayscale)
    downscale_factor: how much to shrink (e.g., 4 means 1/4 size)
    """

    # Original size
    h, w = color_channel.shape[0:2]

    # Downscale and then upscale
    downscaled  = cv2.resize(color_channel, (w // downscale_factor, h // downscale_factor), interpolation=cv2.INTER_AREA)
    restored = cv2.resize(downscaled, (w, h), interpolation=cv2.INTER_LINEAR)

    # Compute mean squared error (MSE) between original and restored image
    mse = np.mean((color_channel - restored) ** 2)

    # Optional: normalize MSE to 0–1 by dividing by max possible value (variance)
    normalized_mse = 1.- mse / np.var(color_channel) 
    # 1 means all information is at coarser spatial scales, 
    # 0 means all information is at finer spatial scales

    return normalized_mse

def symmetry_metric(color_channel, downscale_factor=4):
    """
    Returns a metric of information loss when a color channel from a frame 
    is downscaled and then upscaled.
    
    frame: color channel (e.g., R, G, B, or grayscale)
    downscale_factor: how much to shrink (e.g., 4 means 1/4 size)
    """

    # Original size
    h, w = color_channel.shape[0:2]

    # Downscale and then upscale
    downscaled  = cv2.resize(color_channel, (w // downscale_factor, h // downscale_factor), interpolation=cv2.INTER_AREA)

    # Compute mean squared error (MSE) between original and restored image
    mse = np.mean((downscaled - downscaled[::-1,::-1]) ** 2)

    # Optional: normalize MSE to 0–1 by dividing by max possible value (variance)
    normalized_mse = 1 - mse / np.var(downscaled) 
    # 1 means perfect symmetry at this scale 
    # 0 means no symmetry at this scale

    return normalized_mse


def bgr_to_cmyk(b, g, r):
    """
    Convert BGR to CMYK color space.
    """
    b = b.astype(float) / 255.0
    g = g.astype(float) / 255.0
    r = r.astype(float) / 255.0

    k = 1 - np.max([b, g, r], axis=0) # 1 if black or highest color intensity, 0 if white
    c = (1 - b - k) / (1 - k + 1e-10)
    m = (1 - g - k) / (1 - k + 1e-10)
    y = (1 - r - k) / (1 - k + 1e-10)

    return c, m, y, k

def percentile_data(data):
    """
    Transform the vector <data> into a percentile list where 0 is the lowest and 1 the highest.
    """
    ranks = rankdata(data, method='average')
    percentiles = (ranks-1) / (len(data)-1)
    return percentiles


def compute_metrics(frame,scale_boundary=30):
    """
    Compute different intensity-based metrics on R, G, B, and grayscale images.
    Returns a dictionary of results.
    """
    metrics = {}
    
    b, g, r = cv2.split(frame)
    c, m, y, k = bgr_to_cmyk(b, g, r)
  
    # Convert to grayscale
    gray = 255 - cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # 255 is black, 0 is white

    # Split into R, G, B channels


    for name, color_channel in [("R", r), ("G", g), ("B", b),
                                ("C", c), ("M", m), ("Y", y), ("K", k),
                                ("Gray", gray)]:
        avg_intensity = np.mean(color_channel)
        variance = np.var(color_channel)

        # 1 means all information is at finer spatial scales,
        # 0 means all information is at coarser spatial scales
        large_scale_info = information_metric(color_channel, scale_boundary) # fraction info at small and medium scales

        center_point_symmetry = symmetry_metric(color_channel, scale_boundary) # degree of symmettry for flipping around the center point
        # at the specified spatial scale

        # Store values
        metrics[f"{name}_avg"] = avg_intensity
        metrics[f"{name}_var"] = variance # note that variance is total info (i.e., diff^2 relative to mean)
        metrics[f"{name}_large"] =  large_scale_info # fraction of info at large scales
        metrics[f"{name}_symmetry"] = center_point_symmetry


    return metrics

def process_video_to_midi(video_path, 
                          output_prefix, 
                          frames_per_second=30, 
                          beats_per_frame=4,
                          ticks_per_beat=480, 
                          beats_per_minute=120, 
                          cc_number=7, 
                          midi_channel=0,
                          scale_boundary = 30):
    """
    Process every Nth frame, calculate metrics, and generate multiple MIDI files.
    
    :param video_path: Path to the video file.
    :param output_prefix: Prefix for output MIDI filenames.
    :param frames_per_second (number of frames per second in video)
    :param beats_per_frame (number of beats between each frame that will per processed)
    :param ticks_per_beat (number of midi ticks per beat in DAW)
    :param beats_per_minute (number of beats per minute in DAW)
    :param cc_number: MIDI CC number (default 7 for volume).
    :param channel: MIDI channel (0-15).

    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Error: Could not open video file.")
        return

    # Define metric categories
    metric_names = ["avg", "var", "large", "symmetry"]
    color_channels = ["R", "G", "B", "C", "M", "Y", "K", "Gray"]

    ticks_per_frame = ticks_per_beat *( beats_per_minute / 60.) / frames_per_second # ticks per second / frames per second
    # Calculate the frame interval for processing frames
    seconds_per_analysis_frame = beats_per_frame / (beats_per_minute / 60) # beats per frame / beats per second
    frames_per_analysis_frame_real = seconds_per_analysis_frame * frames_per_second
    # Take every Nth frame, where frames_per_interval_real is the floating point non-integer version of N

    frame_count = 0
    frame_count_list = []


    # assemble dictionary of results for metrics
    metrics = {f"{color_channel}_{metric}": [] for color_channel in color_channels for metric in metric_names}
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        k = frame_count / frames_per_analysis_frame_real
        k_rounded = round(k)
        frame_count_good = round(k_rounded * frames_per_analysis_frame_real)
        if frame_count == frame_count_good :
            print ("Processing frame:", frame_count)
            frame_count_list.append(frame_count)

            metric_results = compute_metrics(frame, scale_boundary)

            #append to the dictionary of results
            for key, value in metric_results.items():
                metrics[key].append(value)

        frame_count += 1

    cap.release()

    # normalize all metrics to be between 0 and 1, with a percentile mapping
    for key, values in metrics.items():
        metric = np.array(values)
        # max_val = np.max(metric)
        # min_val = np.min(metric)
        # normalized_metric = (metric - min_val) / (max_val - min_val)
        # normalize by taking a percentile ranking
        normalized_metric = percentile_data(metric)
        metrics[key] = normalized_metric.tolist()

    # Initialize MIDI files for each metric
    midi_files = {}
    for color_channel in color_channels:
        for metric in metric_names:
            base_filename = f"{output_prefix}_{color_channel}_{metric}"
            midi_files[f"{color_channel}_{metric}"] = MidiFile()
            midi_files[f"{color_channel}_{metric}_inv"] = MidiFile()

            # Add MIDI tracks
            midi_files[f"{color_channel}_{metric}"].tracks.append(MidiTrack())
            midi_files[f"{color_channel}_{metric}_inv"].tracks.append(MidiTrack())

    # Write MIDI messages for each metric
    for key, value in metrics.items():
        midi_val = [round(127 * val) for val in value] # Scale to MIDI range (0-127)
        # Invert the MIDI value for the second file
        midi_val_inv = [round(127 * (1-val)) for val in value]

        # Add to the correct MIDI track
        color_channel_name, metric_name = key.split("_")
        for i, midi_value in enumerate(midi_val):
            if i == 0:
                time_tick = 0
            else:
                time_tick = int(ticks_per_frame * (frame_count_list[i] -frame_count_list[i-1]) )
            midi_files[f"{color_channel_name}_{metric_name}"].tracks[0].append(
                Message('control_change', 
                        control=cc_number, 
                        value=midi_value, 
                        channel=midi_channel, 
                        time=time_tick)
            )
        for i, midi_value_inv in enumerate(midi_val_inv):
            if i == 0:
                time_tick = 0
            else:
                time_tick = int(ticks_per_frame * (frame_count_list[i] -frame_count_list[i-1]) )


            midi_files[f"{color_channel_name}_{metric_name}_inv"].tracks[0].append(
                Message('control_change', 
                        control=cc_number, 
                        value=midi_value_inv, 
                        channel=midi_channel, 
                        time=time_tick)
            )






    # Save all MIDI files
    for key, midi_file in midi_files.items():
        filename = f"{output_prefix}_{key}.mid"
        midi_file.save(filename)
        print(f"Saved: {filename}")

# Example usage
#test_video = "Mz3DllgimbrV2.wmv"
video_file = "He saw Julias everywhere (MzJuliaV2e).wmv"

process_video_to_midi(video_file, 
                      "Julias everywhere", 
                      frames_per_second=30, 
                      beats_per_frame=1,
                      ticks_per_beat=480, 
                      beats_per_minute=82, 
                      cc_number=7, 
                      midi_channel=0,
                      scale_boundary=30) # scale boundary means divide so 30 pixels in a cell
# process_video_to_midi("path_to_your_video.mp4", "output_prefix", nth_frame=30, frames_per_second=30, ticks_per_beat=480, beats_per_minute=120, cc_number=7, channel=0)

