# video to midi code
"""
prompt for ChatGTP:

Here's a Python script that processes every Nth frame of a video file, calculates multiple metrics (average intensity, 
standard deviation, and entropy) for each color color_channel_name (R, G, B, and grayscale) and outputs 24 MIDI files. 
Each metric is stored in two MIDI files: one directly scaled (0-127) and another inverted (127-0).

This script will:

Extract every Nth frame from the video.
Compute various metrics for each color channel.
Map values to MIDI Control Change (CC) messages (both direct and inverted).
Save each metric in a separate MIDI file, with filenames autogenerated.

"""
import cv2
import pandas as pd
import numpy as np
from mido import Message, MidiFile, MidiTrack
from scipy.stats import rankdata

def information_metric(color_channel, downscale_factor=4):
    """
    Returns a metric of information loss when a color channel from a frame 
    is downscaled and then upscaled.
    
    frame: color channel (e.g., R, G, B, or grayscale)
    downscale_factor: how much to shrink (e.g., 4 means 1/4 size)
    """

    # Original size
    h, w = color_channel.shape[0:2]

    # Downscale and then upscale
    downscaled  = cv2.resize(color_channel, (w // downscale_factor, h // downscale_factor), interpolation=cv2.INTER_AREA)
    restored = cv2.resize(downscaled, (w, h), interpolation=cv2.INTER_LINEAR)

    # Compute mean squared error (MSE) between original and restored image
    mse = np.mean((color_channel - restored) ** 2)

    # Optional: normalize MSE to 0–1 by dividing by max possible value (variance)
    normalized_mse = 1.- mse / np.var(color_channel) 
    # 1 means all information is at coarser spatial scales, 
    # 0 means all information is at finer spatial scales

    return normalized_mse

def tranpose_metric(color_channel, downscale_factor=4):
    """
    Returns a metric of information loss when a color channel from a frame 
    is downscaled and then upscaled.
    
    frame: color channel (e.g., R, G, B, or grayscale)
    downscale_factor: how much to shrink (e.g., 4 means 1/4 size)
    """

    # Original size
    h, w = color_channel.shape[0:2]

    # Downscale and then upscale
    downscaled  = cv2.resize(color_channel, (w // downscale_factor, h // downscale_factor), interpolation=cv2.INTER_AREA)

    # Compute mean squared error (MSE) between original and restored image
    mse = np.mean((downscaled - downscaled[::-1,::-1]) ** 2)

    # Optional: normalize MSE to 0–1 by dividing by max possible value (variance)
    normalized_mse = 1 - mse / np.var(downscaled) 
    # 1 means perfect symmetry at this scale 
    # 0 means no symmetry at this scale

    return normalized_mse

def reflect_metric(color_channel, downscale_factor=4):
    """
    Returns a metric of information loss when a color channel from a frame 
    is downscaled and then upscaled.
    
    frame: color channel (e.g., R, G, B, or grayscale)
    downscale_factor: how much to shrink (e.g., 4 means 1/4 size)
    """

    # Original size
    h, w = color_channel.shape[0:2]

    # Downscale and then upscale
    downscaled  = cv2.resize(color_channel, (w // downscale_factor, h // downscale_factor), interpolation=cv2.INTER_AREA)

    # Compute mean squared error (MSE) between original and vertically reflected image
    mse0 = np.mean((downscaled - downscaled[::-1]) ** 2)

    # Compute mean squared error (MSE) between original and horizontally reflected image
    mse1 = np.mean((downscaled - downscaled[:,::-1]) ** 2)

    # Optional: normalize MSE to 0–1 by dividing by max possible value (variance)
    normalized_mse = 1 -(mse0 + mse1) / (2. * np.var(downscaled) )
    # 1 means perfect symmetry at this scale 
    # 0 means no symmetry at this scale

    return normalized_mse

def radial_symmetry_metric(color_channel, scale_factor):
    """
    Compute radial symmetry metric for a color channel with distance bins of width `scale_factor`.
    """
    # Step 1: Create coordinate grid
    y, x = np.indices(color_channel.shape)
    center_y = (color_channel.shape[0] / 2) - 0.5
    center_x = (color_channel.shape[1] / 2) - 0.5

    # Step 2: Compute radial distance from center for each pixel
    r = np.sqrt((x - center_x)**2 + (y - center_y)**2)

    # Step 2b: Bin distances into scale_factor-wide bins
    r_bin = (r / scale_factor).astype(np.int32)

    # Step 3: Compute mean value for each radial bin
    max_bin = r_bin.max()
    radial_mean = np.zeros(max_bin + 1)
    counts = np.bincount(r_bin.ravel())
    sums = np.bincount(r_bin.ravel(), weights=color_channel.ravel())

    # Avoid division by zero
    with np.errstate(divide='ignore', invalid='ignore'):
        radial_mean[:len(sums)] = np.where(counts != 0, sums / counts, 0)

    # Optional: remove zeros or masked bins if they skew the variance
    # valid = counts > 0
    # return np.var(radial_mean[valid])

    return np.var(radial_mean)


def bgr_to_cmyk(b, g, r):
    """
    Convert BGR to CMYK color space.
    """
    b = b.astype(float) / 255.0
    g = g.astype(float) / 255.0
    r = r.astype(float) / 255.0

    k = 1 - np.max([b, g, r], axis=0) # 1 if black or highest color intensity, 0 if white
    c = (1 - b - k) / (1 - k + 1e-10)
    m = (1 - g - k) / (1 - k + 1e-10)
    y = (1 - r - k) / (1 - k + 1e-10)

    return c, m, y, k

def bgr_to_hsv(b, g, r):
    """
    Convert RGB to HSV for 2D numpy arrays.
    Inputs r, g, b: 2D numpy arrays with values in [0, 255]
    Outputs h in degrees [0, 360), s and v in [0.0, 1.0]
    """
    r = r.astype(np.float32) / 255
    g = g.astype(np.float32) / 255
    b = b.astype(np.float32) / 255

    cmax = np.maximum.reduce([r, g, b])
    cmin = np.minimum.reduce([r, g, b])
    delta = cmax - cmin

    # Hue calculation
    h = np.zeros_like(cmax)

    mask = delta != 0
    r_max = (cmax == r) & mask
    g_max = (cmax == g) & mask
    b_max = (cmax == b) & mask

    h[r_max] = (60 * ((g[r_max] - b[r_max]) / delta[r_max])) % 360
    h[g_max] = (60 * ((b[g_max] - r[g_max]) / delta[g_max]) + 120)
    h[b_max] = (60 * ((r[b_max] - g[b_max]) / delta[b_max]) + 240)

    # Saturation calculation
    s = np.zeros_like(cmax)
    nonzero = cmax != 0
    s[nonzero] = delta[nonzero] / cmax[nonzero]

    # Value
    v = cmax

    return h, s, v

# Circular statistics function to compute standard deviation of angle weighted by saturation
# Hue is assumed to be 0-360 degrees, saturation is 0-1
def weighted_circular_std_deg(hue, saturation):
    """Weighted circular standard deviation in degrees"""
    angles_rad = np.deg2rad(hue)
    weights = np.array(saturation)
    z = weights * np.exp(1j * angles_rad)
    R_w = np.abs(np.sum(z) / np.sum(weights))
    return np.rad2deg(np.sqrt(-2 * np.log(R_w)))


def percentile_data(data):
    """
    Transform the vector <data> into a percentile list where 0 is the lowest and 1 the highest.
    """
    ranks = rankdata(data, method='average')
    percentiles = (ranks-1) / (len(data)-1)
    return percentiles


def compute_metrics(frame,scale_boundary=30):
    """
    Compute different intensity-based metrics on R, G, B, and grayscale images.
    Returns a dictionary of results.
    """
    metrics = {}
    
    b, g, r = cv2.split(frame)
    c, m, y, k = bgr_to_cmyk(b, g, r)
    h, s, v = bgr_to_hsv(b, g, r)
  
    # Convert to grayscale
    gray = 255 - cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # 255 is black, 0 is white

    # Split into R, G, B channels

    for color_channel_name, color_channel in [("R", r), ("G", g), ("B", b),
                                ("C", c), ("M", m), ("Y", y), ("K", k),
                                ("Gray", gray)]:
        avg_intensity = np.mean(color_channel)
        variance = np.var(color_channel)

        # 1 means all information is at finer spatial scales,
        # 0 means all information is at coarser spatial scales
        large_scale_info = information_metric(color_channel, scale_boundary) # fraction info at small and medium scales

        transpose_metric_value = tranpose_metric(color_channel, scale_boundary) # degree of symmettry for flipping around the center point
        # at the specified spatial scale
        reflect_metric_value = reflect_metric(color_channel, scale_boundary) # degree of symmettry for flipping around the center point
        # at the specified spatial scale
        radial_symmetry_metric_value = radial_symmetry_metric(color_channel, scale_boundary) # degree of symmettry for flipping around the center point
        # at the specified spatial scale

        # Store values
        metrics[f"{color_channel_name}_avg"] = avg_intensity
        metrics[f"{color_channel_name}_var"] = variance # note that variance is total info (i.e., diff^2 relative to mean)
        metrics[f"{color_channel_name}_large"] =  large_scale_info # fraction of info at large scales
        metrics[f"{color_channel_name}_transpose"] = transpose_metric_value
        metrics[f"{color_channel_name}_reflect"] = reflect_metric_value
        metrics[f"{color_channel_name}_radial"] = radial_symmetry_metric_value

    #monochromicity metric is the standard deviation of hue weighted by saturation
    metrics["HSV_monochromicity"] = weighted_circular_std_deg(h, s) 

    return metrics

def triangular_filter_odd(data, N):
    if N < 1:
        raise ValueError("Filter length N must be at least 1.")
    if N % 2 == 0:
        raise ValueError("Triangular filter requires odd N.")

    data = np.asarray(data)
    half_window = N // 2

    # Create triangular weights
    weights = np.arange(1, half_window + 2)
    weights = np.concatenate([weights, weights[:-1][::-1]])
    weights = weights / weights.sum()  # Normalize to sum to 1

    # Pad data at both ends using edge values
    padded = np.pad(data, pad_width=half_window, mode='edge')

    # Apply convolution
    filtered = np.convolve(padded, weights, mode='valid')
    return filtered

# Export metrics to CSV
def export_metrics_to_csv(frame_count_list, metrics, filename):
    """
    Export frame count and metric data to a CSV file using pandas,
    with metrics sorted alphabetically by key.

    Parameters:
    - frame_count_list (list): List of frame counts.
    - metrics (dict): Dictionary where each value is a list of the same length as frame_count_list.
    - filename (str): Name of the CSV file to write.
    """

    # Sort the metric keys alphabetically
    sorted_keys = sorted(metrics.keys())

    # Create a DataFrame using the sorted keys
    data = {'frame_count_list': frame_count_list}
    for key in sorted_keys:
        data[key] = metrics[key]

    df = pd.DataFrame(data)
    df.to_csv(filename, index=False)

def process_video_to_midi(video_path, 
                          output_prefix, 
                          frames_per_second, 
                          beats_per_frame,
                          ticks_per_beat, 
                          beats_per_minute, 
                          cc_number, 
                          midi_channel,
                          scale_boundary,
                          filter_width):
    """
    Process every Nth frame, calculate metrics, and generate multiple MIDI files.
    
    :param video_path: Path to the video file.
    :param output_prefix: Prefix for output MIDI filenames.
    :param frames_per_second (number of frames per second in video)
    :param beats_per_frame (number of beats between each frame that will per processed)
    :param ticks_per_beat (number of midi ticks per beat in DAW)
    :param beats_per_minute (number of beats per minute in DAW)
    :param cc_number: MIDI CC number (default 7 for volume).
    :param channel: MIDI channel (0-15).
    :param scale_boundary: spatial scale for computing metrics
    :param filter_width: width of boxcar filter for smoothing

    """
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Error: Could not open video file.")
        return

    # Define metric categories
    metric_names = ["avg", "var", "large", "transpose", "reflect", "radial"]
    color_channel_names = ["R", "G", "B", "C", "M", "Y", "K", "Gray"]

    ticks_per_frame = ticks_per_beat *( beats_per_minute / 60.) / frames_per_second # ticks per second / frames per second
    # Calculate the frame interval for processing frames
    seconds_per_analysis_frame = beats_per_frame / (beats_per_minute / 60) # beats per frame / beats per second
    frames_per_analysis_frame_real = seconds_per_analysis_frame * frames_per_second
    # Take every Nth frame, where frames_per_interval_real is the floating point non-integer version of N

    frame_count = 0
    frame_count_list = []


    # assemble dictionary of results for metrics
    metrics = {f"{color_channel_name}_{metric_name}": [] 
               for color_channel_name in color_channel_names for metric_name in metric_names}
    # add metric that is outside of the normal grouping
    metrics["HSV_monochromicity"] = []

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        k = frame_count / frames_per_analysis_frame_real
        k_rounded = round(k)
        frame_count_good = round(k_rounded * frames_per_analysis_frame_real)
        if frame_count == frame_count_good :
            print ("Processing frame:", frame_count)
            frame_count_list.append(frame_count)

            metric_results = compute_metrics(frame, scale_boundary)

            #append to the dictionary of results
            for key, value in metric_results.items():
                metrics[key].append(value)

        frame_count += 1

    cap.release()

    # normalize all metrics to be between 0 and 1, with a percentile mapping
    #iterate over copy to avoid modifying the dictionary while iterating
    metrics_copy = metrics.copy()
    for key, values in metrics_copy.items():
        metric = np.array(values)
        # max_val = np.max(metric)
        # min_val = np.min(metric)
        # normalized_metric = (metric - min_val) / (max_val - min_val)
        # normalize by taking a percentile ranking
        normalized_metric = percentile_data(metric)
        metrics[key] = normalized_metric.tolist()
        # add square and square root of metric to give different scaling choices
        metrics[f"{key}-sqrt"] = np.sqrt(normalized_metric).tolist()
        metrics[f"{key}-square"] = np.square(normalized_metric).tolist()
        metrics[f"{key}-Nsqrt"] = (1.-np.sqrt(1.-normalized_metric))  .tolist()
        metrics[f"{key}-Nsquare"] = (1.-np.square(1.-normalized_metric)).tolist()

    # create derived metrics that involve combining metrics
    for color_channel_name in color_channel_names:
        # find minimum of "transpose", "reflect", "radial" metrics
        for suffix in ["" , "-sqrt", "-square", "-Nsqrt", "-Nsquare"]:
            transpose = metrics[f"{color_channel_name}_transpose{suffix}"]
            reflect = metrics[f"{color_channel_name}_reflect{suffix}"]
            radial = metrics[f"{color_channel_name}_radial{suffix}"]
            symmetry = np.minimum.reduce([transpose, reflect, radial])
            metrics[f"{color_channel_name}_symmetry{suffix}"] = symmetry.tolist()

    # create derived metrics that involve combining color channels
    for metric_name in metric_names + ["symmetry"]:
        # find minimum of "transpose", "reflect", "radial" metrics
        r = metrics[f"R_{metric_name}"]
        g = metrics[f"G_{metric_name}"]
        b = metrics[f"B_{metric_name}"]
        c = metrics[f"C_{metric_name}"]
        m = metrics[f"M_{metric_name}"]
        y = metrics[f"Y_{metric_name}"]

        minRGB = np.minimum.reduce([r, g, b], axis=0)
        metrics[f"minRGB_{metric_name}"] = minRGB.tolist()

        minCMY = np.minimum.reduce([c, m, y], axis=0)
        metrics[f"minCMY_{metric_name}"] = minCMY.tolist()

        maxRGB = np.maximum.reduce([r, g, b], axis=0)
        metrics[f"maxRGB_{metric_name}"] = maxRGB.tolist()

        maxCMY = np.maximum.reduce([c, m, y], axis=0)
        metrics[f"maxCMY_{metric_name}"] = maxCMY.tolist()

    # Smooth the data with a boxcar filter
    if filter_width > 1:
        for key, values in metrics.items():
            metrics[key] = triangular_filter_odd(np.array(values), filter_width).tolist()

    # Create MIDI files for each metric
    midi_files = {}
    for key, value in metrics.items():
        color_channel_name, metric_name = key.split("_")
        
        # Initialize MIDI files for each metric
        midi_files[f"{color_channel_name}_{metric_name}"] = MidiFile()
        midi_files[f"{color_channel_name}_{metric_name}_inv"] = MidiFile()

        # Add MIDI tracks
        midi_files[f"{color_channel_name}_{metric_name}"].tracks.append(MidiTrack())
        midi_files[f"{color_channel_name}_{metric_name}_inv"].tracks.append(MidiTrack())
    
        # Write MIDI messages for each metric
        midi_val = [round(104 * val) for val in value] # Scale to MIDI range (0-104, avoid 105-127)
        # Invert the MIDI value for the second file
        midi_val_inv = [round(104 * (1-val)) for val in value]

        # Add to the correct MIDI track
        for i, midi_value in enumerate(midi_val):
            if i == 0:
                time_tick = 0
            else:
                time_tick = int(ticks_per_frame * (frame_count_list[i] -frame_count_list[i-1]) )
            midi_files[f"{color_channel_name}_{metric_name}"].tracks[0].append(
                Message('control_change', 
                        control=cc_number, 
                        value=midi_value, 
                        channel=midi_channel, 
                        time=time_tick)
            )
        for i, midi_value_inv in enumerate(midi_val_inv):
            if i == 0:
                time_tick = 0
            else:
                time_tick = int(ticks_per_frame * (frame_count_list[i] -frame_count_list[i-1]) )
            midi_files[f"{color_channel_name}_{metric_name}_inv"].tracks[0].append(
                Message('control_change', 
                        control=cc_number, 
                        value=midi_value_inv, 
                        channel=midi_channel, 
                        time=time_tick)
            )

        # Save all MIDI files
        for key, midi_file in midi_files.items():
            filename = f"{output_prefix}_{key}.mid"
            midi_file.save(filename)
            # print(f"Saved: {filename}")

    # Export metrics to CSV
    csv_filename = f"{output_prefix}.csv"
    export_metrics_to_csv(frame_count_list, metrics, csv_filename)
    print(f"Metrics exported to {csv_filename}")



# Example usage
#test_video = "Mz3DllgimbrV2.wmv"
#video_file = "He saw Julias everywhere (MzJuliaV2e).wmv"
video_file = "Mz3DllgimbrV2B.wmv"

process_video_to_midi(video_file, 
                      "Mz3DllgimbrV2B", # output prefix
                      frames_per_second=30, 
                      beats_per_frame=1,
                      ticks_per_beat=480, 
                      beats_per_minute=92,  
                      cc_number=7, 
                      midi_channel=0,
                      scale_boundary=12, # scale boundary means divide so 12x12 pixels in a cell
                      filter_width = 5 ) # smooth the data with a triangular filter of this (odd) width
# process_video_to_midi("path_to_your_video.mp4", "output_prefix", nth_frame=30, frames_per_second=30, ticks_per_beat=480, beats_per_minute=120, cc_number=7, channel=0)

